{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2680c922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 13:05:06.564714: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Input, Flatten, LSTM, Dropout, Bidirectional, LeakyReLU, Reshape, Lambda\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# performance matrices\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, auc\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,matthews_corrcoef\n",
    "from tensorflow.keras.callbacks import Callback,EarlyStopping\n",
    "import random\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, recall_score, matthews_corrcoef, roc_curve, auc\n",
    "from tensorflow.keras import backend as K\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Reshape\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from Bio import SeqIO\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Lambda, LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D,GlobalMaxPooling1D\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from tensorflow.keras import models,layers,optimizers,regularizers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,matthews_corrcoef\n",
    "from tensorflow.keras.callbacks import Callback,EarlyStopping\n",
    "import random\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, recall_score, matthews_corrcoef, roc_curve, auc\n",
    "from tensorflow.keras import backend as K\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Reshape\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from Bio import SeqIO\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Lambda, LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D,GlobalMaxPooling1D\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d45353",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/homes/t326h379/Captor_Independent_Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20de99a",
   "metadata": {},
   "source": [
    "# Load Independent Test Dataset features produced by Ankh PLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f4f666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Captor_Independent_Positive = pd.read_csv('df_Captor_Independent_Positive_Ankh_Features.csv')\n",
    "df_Captor_Independent_Negative = pd.read_csv('df_Captor_Independent_Negative_Ankh_Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c5af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_Captor_Independent_Positive, df_Captor_Independent_Negative]\n",
    "\n",
    "O_linked_independent_test_dataset = pd.concat(frames,ignore_index = True)\n",
    "\n",
    "df_Test_array_Ankh = O_linked_independent_test_dataset.drop([\"Position\",\"PID\",\"S or T\"],axis=1)\n",
    "\n",
    "df_Test_array_Ankh = np.array(df_Test_array_Ankh)\n",
    "\n",
    "X_test_full_Ankh = df_Test_array_Ankh\n",
    "\n",
    "y_test_full_Ankh = np.array([1]*340+[0]*1307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7232a6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1647, 1536), (1647,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_full_Ankh.shape, y_test_full_Ankh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43355f",
   "metadata": {},
   "source": [
    "# Load Independent Test Dataset features produced by ProtT5 PLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "927f4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Independent_Test_Set_Positive_ProtT5 = pd.read_csv('df_Captor_Independent_Test_Set_Positive_ProtT5_Features.csv')\n",
    "df_Independent_Test_Set_Negative_ProtT5 = pd.read_csv('df_Independent_Test_Set_Negative_ProtT5_Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a875e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_Independent_Test_Set_Positive_ProtT5, df_Independent_Test_Set_Negative_ProtT5]\n",
    "\n",
    "O_linked_testing_ProtT5 = pd.concat(frames,ignore_index = True)\n",
    "\n",
    "df_Test_array_ProtT5 = O_linked_testing_ProtT5.drop([\"Position\",\"PID\",\"S or T\"],axis=1)\n",
    "df_Test_array_ProtT5 = np.array(df_Test_array_ProtT5)\n",
    "\n",
    "X_test_full_ProtT5 = df_Test_array_ProtT5\n",
    "\n",
    "y_test_full_ProtT5 = np.array([1]*340+[0]*1307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48b94a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1647, 1024), (1647,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_full_ProtT5.shape, y_test_full_ProtT5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105c06e",
   "metadata": {},
   "source": [
    "# Load the trained stacked generalization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bdd684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacked_Generalization_Trained_Model = load_model(\"Captor_Independent_Comparision_with_Stacked_Genralization_Bioinformatics_Review_224949Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a39f9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_209\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_419 (InputLayer)         [(None, 1536)]       0           []                               \n",
      "                                                                                                  \n",
      " ensemble_1_dense_836 (Dense)   (None, 512)          786944      ['input_419[0][0]']              \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_1254 (Dropo  (None, 512)         0           ['ensemble_1_dense_836[0][0]']   \n",
      " ut)                                                                                              \n",
      "                                                                                                  \n",
      " ensemble_1_dense_837 (Dense)   (None, 256)          131328      ['ensemble_1_dropout_1254[0][0]']\n",
      "                                                                                                  \n",
      " ensemble_1_dropout_1255 (Dropo  (None, 256)         0           ['ensemble_1_dense_837[0][0]']   \n",
      " ut)                                                                                              \n",
      "                                                                                                  \n",
      " input_52 (InputLayer)          [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " ensemble_1_Dense_1 (Dense)     (None, 32)           8224        ['ensemble_1_dropout_1255[0][0]']\n",
      "                                                                                                  \n",
      " ensemble_2_Dense_1 (Dense)     (None, 64)           65600       ['input_52[0][0]']               \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_1256 (Dropo  (None, 32)          0           ['ensemble_1_Dense_1[0][0]']     \n",
      " ut)                                                                                              \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_51 (Dropout  (None, 64)          0           ['ensemble_2_Dense_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_1_Dense_2 (Dense)     (None, 2)            66          ['ensemble_1_dropout_1256[0][0]']\n",
      "                                                                                                  \n",
      " ensemble_2_Dense_2 (Dense)     (None, 2)            130         ['ensemble_2_dropout_51[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_209 (Concatenate)  (None, 4)            0           ['ensemble_1_Dense_2[0][0]',     \n",
      "                                                                  'ensemble_2_Dense_2[0][0]']     \n",
      "                                                                                                  \n",
      " dense_418 (Dense)              (None, 4)            20          ['concatenate_209[0][0]']        \n",
      "                                                                                                  \n",
      " dense_419 (Dense)              (None, 2)            10          ['dense_418[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 992,322\n",
      "Trainable params: 30\n",
      "Non-trainable params: 992,292\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Stacked_Generalization_Trained_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e011735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stacked_model(model, inputX):\n",
    "    # prepare input data\n",
    "    X = inputX\n",
    "    # make prediction\n",
    "    return model.predict(X, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cb291f",
   "metadata": {},
   "source": [
    "# Check all the evaluation metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d194954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.5219666073143104\n",
      "\n",
      "Confusion Matrix : \n",
      " [[1096  211]\n",
      " [  88  252]]\n",
      "\n",
      "Accuracy on test set:    0.8184578020643595\n",
      "\n",
      "\n",
      "Sensitivity:    0.7411764705882353 \t Specificity:    0.8385615914307575\n",
      "\n",
      "Precision:    0.5442764578833693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88      1307\n",
      "           1       0.54      0.74      0.63       340\n",
      "\n",
      "    accuracy                           0.82      1647\n",
      "   macro avg       0.73      0.79      0.75      1647\n",
      "weighted avg       0.85      0.82      0.83      1647\n",
      "\n",
      "Area Under Curve:    0.7898690310094965\n"
     ]
    }
   ],
   "source": [
    "y_independent = y_test_full_ProtT5\n",
    "inputX = [X_test_full_Ankh,X_test_full_ProtT5]\n",
    "Y_pred = predict_stacked_model(Stacked_Generalization_Trained_Model, inputX)\n",
    "\n",
    "Y_pred = (Y_pred > 0.5)\n",
    "y_pred = [np.argmax(y, axis=None, out=None) for y in Y_pred]\n",
    "y_pred = np.array(y_pred)\n",
    "y_independent = y_test_full_ProtT5\n",
    "confusion = confusion_matrix(y_independent,y_pred)\n",
    "\n",
    "print(\"Matthews Correlation : \",matthews_corrcoef(y_independent, y_pred))\n",
    "print()\n",
    "print(\"Confusion Matrix : \\n\",confusion_matrix(y_independent, y_pred))\n",
    "print()\n",
    "print(\"Accuracy on test set:   \",accuracy_score(y_independent, y_pred))\n",
    "print()\n",
    "\n",
    "cm = confusion_matrix(y_independent, y_pred)\n",
    "\n",
    "TP = cm[1][1]\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "\n",
    "mcc = matthews_corrcoef(y_independent, y_pred)\n",
    "\n",
    "Sensitivity = TP/(TP+FN)\n",
    "\n",
    "Specificity = TN/(TN+FP)\n",
    "\n",
    "Precision = TP/(TP+FP)\n",
    "\n",
    "print()\n",
    "print(\"Sensitivity:   \",Sensitivity,\"\\t\",\"Specificity:   \",Specificity)\n",
    "print()\n",
    "print(\"Precision:   \",Precision)\n",
    "print()\n",
    "print(classification_report(y_independent, y_pred))\n",
    "\n",
    "ANN_model_Prob_auc = roc_auc_score(y_independent, y_pred)\n",
    "\n",
    "print(\"Area Under Curve:   \",ANN_model_Prob_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad274cb",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4-TensorFlow-2.11.0 [jupyter_python]",
   "language": "python",
   "name": "sys_python_3.10.4-tensorflow-2.11.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
